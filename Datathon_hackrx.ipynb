{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_aMxEXj1-Xh3",
        "outputId": "fae679a8-2a43-4965-f120-5ed2af0d30fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.12/dist-packages (1.7.2)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.12/dist-packages (1.17.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.24.0+cu126)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from easyocr) (4.12.0.88)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.16.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from easyocr) (11.3.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.25.2)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.6.7)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from easyocr) (6.0.3)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.1.2)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.3.0.post6)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.5.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->easyocr) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "pip install easyocr pdf2image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "x1c1rdkA-3Xq",
        "outputId": "8f72a362-058d-4df7-aa78-f36fc4c90347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4lx99oA_D3E",
        "outputId": "b39f275d-8958-4263-e884-4e59cd1e46e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/pdfinfo\n"
          ]
        }
      ],
      "source": [
        "!which pdfinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrM1fP9n1ZVA"
      },
      "source": [
        "EASYOCR (PROBLEM WAS LEAVING SINGLE DIGIT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2EqqwXah-fCl"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class EasyOCRExtractor:\n",
        "    def __init__(self, pdf_path, languages=['en'], gpu=False):\n",
        "        self.pdf_path = pdf_path\n",
        "        self.reader = easyocr.Reader(languages, gpu=gpu)\n",
        "        print(\"âœ“ EasyOCR initialized\")\n",
        "\n",
        "    def extract_all(self, dpi=500, poppler_path=None):\n",
        "        print(f\"Converting PDF to images (DPI: {dpi})...\")\n",
        "\n",
        "        if poppler_path:\n",
        "            pages = convert_from_path(self.pdf_path, dpi=500, poppler_path=poppler_path)\n",
        "        else:\n",
        "            pages = convert_from_path(self.pdf_path, dpi=500)\n",
        "\n",
        "        print(f\"Processing {len(pages)} pages...\")\n",
        "        results = []\n",
        "\n",
        "        for page_num, page_image in enumerate(pages, 1):\n",
        "            text = self._extract_text_from_page(page_image)\n",
        "            results.append({\n",
        "                \"page_number\": page_num,\n",
        "                \"text\": text\n",
        "            })\n",
        "            print(f\"âœ“ Page {page_num} extracted\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _extract_text_from_page(self, image: Image):\n",
        "        img_array = np.array(image)\n",
        "        result = self.reader.readtext(img_array)\n",
        "\n",
        "        # collect ONLY text content in reading order\n",
        "        lines = [item[1] for item in result]\n",
        "\n",
        "        return \"\\n\".join(lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "bfaaa6cb",
        "outputId": "c3250f49-5493-4354-aa86-ae8b2336dbe9"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print(f'User uploaded file \"{fn}\"')\n",
        "  # Assuming the user uploads 'train_sample_1.pdf'\n",
        "  # You might need to adjust the filename if it's different"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8d44eb19-fbc8-4203-a8bc-22a2c3b80803\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8d44eb19-fbc8-4203-a8bc-22a2c3b80803\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Sample Document 1.pdf to Sample Document 1.pdf\n",
            "Saving train_sample_1.pdf to train_sample_1 (1).pdf\n",
            "Saving SAmple Document 2.pdf to SAmple Document 2.pdf\n",
            "Saving Sample Document 3.pdf to Sample Document 3.pdf\n",
            "User uploaded file \"Sample Document 1.pdf\"\n",
            "User uploaded file \"train_sample_1 (1).pdf\"\n",
            "User uploaded file \"SAmple Document 2.pdf\"\n",
            "User uploaded file \"Sample Document 3.pdf\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiDrUyMP-kkj",
        "outputId": "ed057afc-4d3f-41cc-81ed-d1fa97a4ccd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Using CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ EasyOCR initialized\n",
            "Converting PDF to images (DPI: 500)...\n",
            "Processing 2 pages...\n",
            "âœ“ Page 1 extracted\n"
          ]
        }
      ],
      "source": [
        "extractor = EasyOCRExtractor(\"/content/train_sample_1.pdf\", languages=['en'], gpu=False)\n",
        "pages = extractor.extract_all()\n",
        "\n",
        "for p in pages:\n",
        "    print(\"PAGE:\", p[\"page_number\"])\n",
        "    print(p[\"text\"])\n",
        "    print(\"------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fJLhjr_-ugU"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "\n",
        "# initialise reader once\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# run OCR on an image\n",
        "result = reader.readtext(\"/content/sample_3.png\")\n",
        "\n",
        "# extract only text\n",
        "extracted_text = \"\\n\".join([item[1] for item in result])\n",
        "\n",
        "print(extracted_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBeYZ8psDN86"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "\n",
        "# initialise reader once\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# run OCR on an image\n",
        "result = reader.readtext(\"/content/sample_1.png\")\n",
        "\n",
        "# extract only text\n",
        "extracted_text = \"\\n\".join([item[1] for item in result])\n",
        "\n",
        "print(extracted_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64CkbAP2EGay"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "\n",
        "# initialise reader once\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# run OCR on an image\n",
        "result = reader.readtext(\"/content/sample_2.png\")\n",
        "\n",
        "# extract only text\n",
        "extracted_text = \"\\n\".join([item[1] for item in result])\n",
        "\n",
        "print(extracted_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vmjITzJFD0q"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# load image\n",
        "img_path = \"/content/sample_2.png\"\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "results = reader.readtext(img)\n",
        "\n",
        "boxes = []  # store normalized bounding boxes\n",
        "\n",
        "# collect bounding boxes\n",
        "for (bbox, text, conf) in results:\n",
        "    x1, y1 = bbox[0]\n",
        "    x2, y2 = bbox[2]\n",
        "    boxes.append((int(x1), int(y1), int(x2), int(y2)))\n",
        "\n",
        "\n",
        "# sort boxes by y (top to bottom)\n",
        "boxes = sorted(boxes, key=lambda b: b[1])\n",
        "\n",
        "# group into rows\n",
        "rows = []\n",
        "current = [boxes[0]]\n",
        "\n",
        "for b in boxes[1:]:\n",
        "    # threshold for same row (adjust if needed)\n",
        "    if abs(b[1] - current[-1][1]) < 20:\n",
        "        current.append(b)\n",
        "    else:\n",
        "        rows.append(current)\n",
        "        current = [b]\n",
        "rows.append(current)\n",
        "\n",
        "# draw boxes around each \"cell\"\n",
        "for row in rows:\n",
        "    for (x1, y1, x2, y2) in row:\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "\n",
        "cv2.imwrite(\"cells_detected.png\", img)\n",
        "print(\"saved as cells_detected.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYeT6e8xFja_"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img_path = \"/content/sample_2.png\"\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "results = reader.readtext(img)\n",
        "\n",
        "boxes = []\n",
        "\n",
        "# collect boxes\n",
        "for (bbox, text, conf) in results:\n",
        "    x1, y1 = bbox[0]\n",
        "    x2, y2 = bbox[2]\n",
        "    boxes.append([int(x1), int(y1), int(x2), int(y2), text])\n",
        "\n",
        "# sort by x so columns come together\n",
        "boxes = sorted(boxes, key=lambda b: b[0])\n",
        "\n",
        "merged = []\n",
        "used = set()\n",
        "vertical_threshold = 1  # tweak if needed\n",
        "\n",
        "for i, b1 in enumerate(boxes):\n",
        "    if i in used:\n",
        "        continue\n",
        "\n",
        "    x1, y1, x2, y2, text1 = b1\n",
        "    group = [b1]\n",
        "\n",
        "    for j, b2 in enumerate(boxes[i+1:], start=i+1):\n",
        "        xx1, yy1, xx2, yy2, text2 = b2\n",
        "\n",
        "        # same column = strong horizontal overlap\n",
        "        horizontal_overlap = min(x2, xx2) - max(x1, xx1)\n",
        "        if horizontal_overlap > 10:\n",
        "            # vertically close = stack to merge\n",
        "            if abs(yy1 - y2) < vertical_threshold or abs(y1 - yy2) < vertical_threshold:\n",
        "                group.append(b2)\n",
        "                used.add(j)\n",
        "\n",
        "    # merge group text & bbox\n",
        "    xs = [g[0] for g in group] + [g[2] for g in group]\n",
        "    ys = [g[1] for g in group] + [g[3] for g in group]\n",
        "\n",
        "    merged_x1, merged_y1 = min(xs), min(ys)\n",
        "    merged_x2, merged_y2 = max(xs), max(ys)\n",
        "    merged_text = \" \".join([g[4] for g in sorted(group, key=lambda x: x[1])])\n",
        "\n",
        "    merged.append([merged_x1, merged_y1, merged_x2, merged_y2, merged_text])\n",
        "\n",
        "\n",
        "# draw merged bounding boxes\n",
        "for (x1, y1, x2, y2, text) in merged:\n",
        "    cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "\n",
        "cv2.imwrite(\"merged_cells.png\", img)\n",
        "print(\"saved as merged_cells.png\")\n",
        "\n",
        "# print merged text for confirmation\n",
        "for box in merged:\n",
        "    print(box[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2RfsiKKHIds"
      },
      "outputs": [],
      "source": [
        "def merge_vertical(boxes, threshold=1):\n",
        "    merged = []\n",
        "    used = set()\n",
        "\n",
        "    # Sort by X (left to right)\n",
        "    boxes = sorted(boxes, key=lambda b: b[0])\n",
        "\n",
        "    for i, b1 in enumerate(boxes):\n",
        "        if i in used:\n",
        "            continue\n",
        "\n",
        "        x1, y1, x2, y2, text1 = b1\n",
        "        group = [b1]\n",
        "\n",
        "        for j, b2 in enumerate(boxes[i+1:], start=i+1):\n",
        "            xx1, yy1, xx2, yy2, text2 = b2\n",
        "\n",
        "            # strong horizontal overlap (same column)\n",
        "            horiz_overlap = min(x2, xx2) - max(x1, xx1)\n",
        "\n",
        "            # should be same column\n",
        "            if horiz_overlap > 10:\n",
        "                # small vertical gap\n",
        "                if abs(yy1 - y2) < threshold or abs(y1 - yy2) < threshold:\n",
        "                    group.append(b2)\n",
        "                    used.add(j)\n",
        "\n",
        "        # merge group\n",
        "        xs = [g[0] for g in group] + [g[2] for g in group]\n",
        "        ys = [g[1] for g in group] + [g[3] for g in group]\n",
        "\n",
        "        merged_x1 = min(xs)\n",
        "        merged_y1 = min(ys)\n",
        "        merged_x2 = max(xs)\n",
        "        merged_y2 = max(ys)\n",
        "\n",
        "        # sort text top â†’ bottom, join with space\n",
        "        merged_text = \" \".join([g[4] for g in sorted(group, key=lambda t: t[1])])\n",
        "\n",
        "        merged.append([merged_x1, merged_y1, merged_x2, merged_y2, merged_text])\n",
        "\n",
        "    return merged\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmAWbk67Ht6O"
      },
      "outputs": [],
      "source": [
        "def group_rows(boxes, row_threshold=18):\n",
        "    # Sort top â†’ bottom\n",
        "    boxes = sorted(boxes, key=lambda b: b[1])\n",
        "\n",
        "    rows = []\n",
        "    current = [boxes[0]]\n",
        "\n",
        "    for b in boxes[1:]:\n",
        "        y = b[1]\n",
        "\n",
        "        # compare with last element in current row\n",
        "        last_y = current[-1][1]\n",
        "\n",
        "        if abs(y - last_y) < row_threshold:\n",
        "            current.append(b)\n",
        "        else:\n",
        "            rows.append(current)\n",
        "            current = [b]\n",
        "\n",
        "    rows.append(current)\n",
        "    return rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pII65hiYHvuf"
      },
      "outputs": [],
      "source": [
        "def sort_row_cells(rows):\n",
        "    clean = []\n",
        "    for row in rows:\n",
        "        clean.append(sorted(row, key=lambda b: b[0]))  # sort by x\n",
        "    return clean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPlyku-7Hxaz"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "import cv2\n",
        "\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "img = cv2.imread(\"/content/sample_2.png\")\n",
        "\n",
        "raw = reader.readtext(img)\n",
        "\n",
        "boxes = []\n",
        "for (bbox, text, conf) in raw:\n",
        "    x1, y1 = bbox[0]\n",
        "    x2, y2 = bbox[2]\n",
        "    boxes.append([int(x1), int(y1), int(x2), int(y2), text])\n",
        "\n",
        "# step 1 â€” merge vertical\n",
        "merged = merge_vertical(boxes)\n",
        "\n",
        "# step 2 â€” group into table rows\n",
        "rows = group_rows(merged)\n",
        "\n",
        "# step 3 â€” reorder row cells left->right\n",
        "table = sort_row_cells(rows)\n",
        "\n",
        "# print table exactly as a grid\n",
        "for row in table:\n",
        "    print([cell[4] for cell in row])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9qalMfVH4AR"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "import cv2\n",
        "\n",
        "img_path = \"/content/sample_2.png\"\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "reader = easyocr.Reader(['en'], gpu=False)\n",
        "results = reader.readtext(img)\n",
        "\n",
        "for (bbox, text, conf) in results:\n",
        "    # bbox = 4 points: top-left, top-right, bottom-right, bottom-left\n",
        "    pts = bbox\n",
        "\n",
        "    # convert to integers\n",
        "    pts = [(int(x), int(y)) for (x, y) in pts]\n",
        "\n",
        "    # extract corners\n",
        "    (x1, y1) = pts[0]   # top-left\n",
        "    (x2, y2) = pts[2]   # bottom-right\n",
        "\n",
        "    # FIX: ensure rectangle has thickness & valid coords\n",
        "    # expand small boxes a little\n",
        "    if x2 - x1 < 10:\n",
        "        x2 += 2\n",
        "        x1 -= 2\n",
        "    if y2 - y1 < 10:\n",
        "        y2 += 2\n",
        "        y1 -= 2\n",
        "\n",
        "    cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "\n",
        "# save result\n",
        "cv2.imwrite(\"debug_boxes.png\", img)\n",
        "print(\"Saved as debug_boxes.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u54k7WjgIi0p"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "import cv2\n",
        "\n",
        "img_path = \"/content/sample_2.png\"\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "results = reader.readtext(img_path)\n",
        "\n",
        "print(\"TOTAL DETECTIONS:\", len(results))\n",
        "for i, (bbox, text, conf) in enumerate(results):\n",
        "    print(i, text, conf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xV7zSD1JFSn"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(\"/content/sample_2.png\")\n",
        "img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)\n",
        "cv2.imwrite(\"/content/sample_2.png\", img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1SEqY7YJ5DJ"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# image path\n",
        "img_path = \"/content/processed_output.png\"\n",
        "\n",
        "# OCR reader\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# run OCR\n",
        "results = reader.readtext(\n",
        "    img_path,\n",
        "    detail=1,\n",
        "    contrast_ths=0.1,\n",
        "    adjust_contrast=0.7,\n",
        "    min_size=3\n",
        ")\n",
        "\n",
        "# print detections\n",
        "print(\"TOTAL DETECTIONS:\", len(results))\n",
        "for i, (bbox, text, conf) in enumerate(results):\n",
        "    print(i, text, conf)\n",
        "\n",
        "# -------------------------------\n",
        "# DRAW BOUNDING BOXES ON IMAGE\n",
        "# -------------------------------\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "for (bbox, text, conf) in results:\n",
        "    pts = np.array(bbox).astype(int)\n",
        "\n",
        "    # fix rectangle points\n",
        "    x_min = pts[:,0].min()\n",
        "    x_max = pts[:,0].max()\n",
        "    y_min = pts[:,1].min()\n",
        "    y_max = pts[:,1].max()\n",
        "\n",
        "    # draw rectangle\n",
        "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0,255,0), 2)\n",
        "\n",
        "# convert BGR â†’ RGB for notebook\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# show output image\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(img_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F15B4ktCKCxs"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def preprocess(img):\n",
        "    img = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.equalizeHist(gray)\n",
        "\n",
        "    th = cv2.adaptiveThreshold(\n",
        "        gray, 255,\n",
        "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY,\n",
        "        31, 10\n",
        "    )\n",
        "\n",
        "    kernel = np.ones((2,2), np.uint8)\n",
        "    thicken = cv2.dilate(th, kernel, iterations=1)\n",
        "\n",
        "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))\n",
        "    remove_vertical = cv2.morphologyEx(thicken, cv2.MORPH_OPEN, vertical_kernel)\n",
        "\n",
        "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))\n",
        "    remove_horizontal = cv2.morphologyEx(thicken, cv2.MORPH_OPEN, horizontal_kernel)\n",
        "\n",
        "    cleaned = thicken - remove_vertical - remove_horizontal\n",
        "\n",
        "    cleaned = cv2.resize(cleaned, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    return cleaned\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nILY7ifGL8H2"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "img = cv2.imread(\"/content/sample_3.png\")\n",
        "preprocess(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6DwUykDMm29"
      },
      "outputs": [],
      "source": [
        "cv2.imwrite(\"processed_output.png\", img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSfBF195nW5R"
      },
      "source": [
        "TESSARACT WORKING WRONG HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tchFHKypSQce"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "def preprocess_scanned_image(image_path, dpi=300):\n",
        "    # Read image\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # 1. RESOLUTION ENHANCEMENT (if low DPI)\n",
        "    height, width = img.shape[:2]\n",
        "    if height < 2000:  # Low resolution check\n",
        "        img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # 2. GRAYSCALE CONVERSION\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 3. NOISE REMOVAL (crucial for scanned docs)\n",
        "    denoised = cv2.medianBlur(gray, 3)\n",
        "    # Alternative: Gaussian blur\n",
        "    # denoised = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "\n",
        "    # 4. CONTRAST ENHANCEMENT\n",
        "    # CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    contrast_enhanced = clahe.apply(denoised)\n",
        "\n",
        "    # 5. THRESHOLDING (binarization)\n",
        "    # Global threshold\n",
        "    _, thresh_global = cv2.threshold(contrast_enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Adaptive threshold (better for uneven lighting in scans)\n",
        "    thresh_adaptive = cv2.adaptiveThreshold(contrast_enhanced, 255,\n",
        "                                          cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                          cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "    # 6. DESKEWING (correct rotation)\n",
        "    def deskew(image):\n",
        "        coords = np.column_stack(np.where(image > 0))\n",
        "        if len(coords) == 0:\n",
        "            return image\n",
        "\n",
        "        angle = cv2.minAreaRect(coords)[-1]\n",
        "        if angle < -45:\n",
        "            angle = -(90 + angle)\n",
        "        else:\n",
        "            angle = -angle\n",
        "\n",
        "        (h, w) = image.shape[:2]\n",
        "        center = (w // 2, h // 2)\n",
        "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "        rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC,\n",
        "                               borderMode=cv2.BORDER_REPLICATE)\n",
        "        return rotated\n",
        "\n",
        "    deskewed = deskew(thresh_adaptive)\n",
        "\n",
        "    # 7. MORPHOLOGICAL OPERATIONS (clean up text)\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    cleaned = cv2.morphologyEx(deskewed, cv2.MORPH_CLOSE, kernel)\n",
        "    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    return cleaned, thresh_global, thresh_adaptive\n",
        "\n",
        "def ocr_scanned_document(image_path):\n",
        "    # Preprocess with multiple methods\n",
        "    cleaned, global_thresh, adaptive_thresh = preprocess_scanned_image(image_path)\n",
        "\n",
        "    # Try OCR on different preprocessed versions\n",
        "    images_to_try = {\n",
        "        'cleaned': cleaned,\n",
        "        'global_thresh': global_thresh,\n",
        "        'adaptive_thresh': adaptive_thresh\n",
        "    }\n",
        "\n",
        "    best_result = \"\"\n",
        "    best_method = \"\"\n",
        "\n",
        "    for method, img in images_to_try.items():\n",
        "        # Tesseract config for scanned documents\n",
        "        config = '--oem 3 --psm 6 -c tessedit_do_invert=0'\n",
        "\n",
        "        text = pytesseract.image_to_string(img, config=config)\n",
        "\n",
        "        # Simple heuristic: pick result with most valid content\n",
        "        if len(text.strip()) > len(best_result.strip()):\n",
        "            best_result = text\n",
        "            best_method = method\n",
        "\n",
        "    print(f\"Best preprocessing method: {best_method}\")\n",
        "    return best_result\n",
        "\n",
        "# Usage\n",
        "result = ocr_scanned_document(\"/content/sample3rd.png\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-U2cACLnTJL"
      },
      "source": [
        "FINAL WORKING WITH TESSARACT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chIiVOowUx79"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install Tesseract and dependencies in Colab\n",
        "!sudo apt update\n",
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt install libtesseract-dev\n",
        "\n",
        "# Step 2: Install Python packages\n",
        "!pip install pytesseract\n",
        "!pip install opencv-python\n",
        "!pip install Pillow\n",
        "\n",
        "# Step 3: Import libraries\n",
        "import cv2\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 4: Set tesseract path for Colab\n",
        "pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n",
        "\n",
        "# Step 5: Verify installation\n",
        "print(\"Tesseract version:\", pytesseract.get_tesseract_version())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgLLxM46msWX"
      },
      "outputs": [],
      "source": [
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EwtrTqPU4O9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import fitz\n",
        "import io\n",
        "\n",
        "def simple_pdf_ocr(pdf_path, output_file=\"extracted_text.txt\"):\n",
        "    \"\"\"\n",
        "    Simple PDF to text extraction\n",
        "    \"\"\"\n",
        "    # Convert PDF to images\n",
        "    pdf_doc = fitz.open(pdf_path)\n",
        "    all_text = {}\n",
        "\n",
        "    for page_num in range(len(pdf_doc)):\n",
        "        page = pdf_doc[page_num]\n",
        "        # Convert to image\n",
        "        pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72))\n",
        "        img_data = pix.tobytes(\"ppm\")\n",
        "        img_pil = Image.open(io.BytesIO(img_data))\n",
        "        img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Preprocess\n",
        "        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
        "        _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "        # OCR\n",
        "        text = pytesseract.image_to_string(thresh, config='--psm 6')\n",
        "        all_text[page_num + 1] = text\n",
        "\n",
        "        print(f\"Page {page_num + 1} processed\")\n",
        "\n",
        "    pdf_doc.close()\n",
        "\n",
        "    # Save to file\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        for page_num, text in all_text.items():\n",
        "            f.write(f\"\\n{'='*60}\\n\")\n",
        "            f.write(f\"PAGE {page_num}\\n\")\n",
        "            f.write(f\"{'='*60}\\n\\n\")\n",
        "            f.write(text)\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    print(f\"Text extracted to: {output_file}\")\n",
        "    return all_text\n",
        "\n",
        "# Quick usage in Colab:\n",
        "\n",
        "# uploaded = files.upload()\n",
        "# pdf_file = list(uploaded.keys())[0]\n",
        "result = simple_pdf_ocr('/content/train_sample_11.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXiH36XpmfpF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "# QUICK TESTER - Reads from extracted.txt\n",
        "def test_extraction():\n",
        "    print(\"ðŸ” TESTING EXTRACTION FROM extracted.txt...\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Read the file\n",
        "    with open('extracted_text.txt', 'r') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    # Simple pattern matching for your bill format\n",
        "    pattern = r'(\\d+)\\s+([A-Z\\s]+?)\\s+(\\d+\\.\\d{2})\\s+([\\d,]+\\.\\d{2})\\s+(\\d+)\\s+([\\d,]+\\.\\d{2})'\n",
        "    matches = re.findall(pattern, text)\n",
        "\n",
        "    bill_items = []\n",
        "\n",
        "    for match in matches:\n",
        "        item_code, item_name, quantity, rate, discount, amount = match\n",
        "\n",
        "        # Clean item name\n",
        "        item_name = item_name.strip().replace('CHARGES', '').strip()\n",
        "\n",
        "        bill_items.append({\n",
        "            \"item_name\": item_name,\n",
        "            \"item_quantity\": float(quantity),\n",
        "            \"item_rate\": float(rate.replace(',', '')),\n",
        "            \"item_amount\": float(amount.replace(',', ''))\n",
        "        })\n",
        "\n",
        "    # Display results\n",
        "    print(f\"ðŸ“Š Found {len(bill_items)} bill items:\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    for i, item in enumerate(bill_items[:15], 1):  # Show first 15 items\n",
        "        print(f\"{i:2d}. {item['item_name']:25} | \"\n",
        "              f\"Qty: {item['item_quantity']:4} | \"\n",
        "              f\"Rate: {item['item_rate']:8.2f} | \"\n",
        "              f\"Amount: {item['item_amount']:8.2f}\")\n",
        "\n",
        "    if len(bill_items) > 15:\n",
        "        print(f\"... and {len(bill_items) - 15} more items\")\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"ðŸ’° TOTAL AMOUNT: â‚¹{sum(item['item_amount'] for item in bill_items):,.2f}\")\n",
        "\n",
        "    return bill_items\n",
        "\n",
        "# RUN THE TEST\n",
        "result = test_extraction()\n",
        "\n",
        "# Show JSON output for first 3 items\n",
        "print(\"\\nðŸŽ¯ SAMPLE JSON OUTPUT (first 3 items):\")\n",
        "print(json.dumps({\"bill_items\": result[:3]}, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptP2Kzlu1yTc"
      },
      "source": [
        "PADDLEOCR (WORKING GOOD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7jMk-masQ0_"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y pillow\n",
        "!pip install pillow==9.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1KTIijPtpv7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# å¯¹äºŽ Linux ç³»ç»Ÿï¼Œæ‰§è¡Œï¼š\n",
        "!pip install https://paddle-whl.bj.bcebos.com/nightly/cu126/safetensors/safetensors-0.6.2.dev0-cp38-abi3-linux_x86_64.whl\n",
        "# å¯¹äºŽWindows ç³»ç»Ÿï¼Œæ‰§è¡Œï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "andkZjqNvuRz"
      },
      "outputs": [],
      "source": [
        "# Uninstall conflicting packages\n",
        "!pip uninstall paddleocr paddlex langchain langchain-community -y\n",
        "\n",
        "# Install compatible versions\n",
        "!pip install paddleocr==2.7.0.3\n",
        "!pip install langchain==0.1.0\n",
        "!pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmeBWzWJwtu8"
      },
      "outputs": [],
      "source": [
        "!pip install paddlepaddle==3.2.1\n",
        "!python -m pip install -U \"paddleocr[doc-parser]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Chpure8xx-hs"
      },
      "outputs": [],
      "source": [
        "from paddleocr import PaddleOCR\n",
        "\n",
        "# Initialize the object once\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1F124MKOyI8p"
      },
      "outputs": [],
      "source": [
        "def perform_ocr(image):\n",
        "    result = ocr.ocr(image)\n",
        "    print(f\"Result type: {type(result)}\")\n",
        "    print(f\"Result: {result}\")\n",
        "    return result\n",
        "\n",
        "result = perform_ocr(\"/content/sample_2.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pKd0MbwzHRP"
      },
      "outputs": [],
      "source": [
        "if result and len(result) > 0:\n",
        "    data = result[0]\n",
        "\n",
        "    texts = data.get('rec_texts', [])\n",
        "    scores = data.get('rec_scores', [])\n",
        "    polys = data.get('rec_polys', [])\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"EXTRACTED TEXT:\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for idx, (text, score) in enumerate(zip(texts, scores)):\n",
        "        print(f\"{idx+1}. {text} (confidence: {score:.2%})\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ALL TEXT COMBINED:\")\n",
        "    print(\"=\"*60)\n",
        "    print(' '.join(texts))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHhuLzJOzpDv"
      },
      "outputs": [],
      "source": [
        "result1 = perform_ocr(\"/content/sample_1.png\")\n",
        "if result1 and len(result1) > 0:\n",
        "    data = result1[0]\n",
        "\n",
        "    texts = data.get('rec_texts', [])\n",
        "    scores = data.get('rec_scores', [])\n",
        "    polys = data.get('rec_polys', [])\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"EXTRACTED TEXT:\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for idx, (text, score) in enumerate(zip(texts, scores)):\n",
        "        print(f\"{idx+1}. {text} (confidence: {score:.2%})\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ALL TEXT COMBINED:\")\n",
        "    print(\"=\"*60)\n",
        "    print(' '.join(texts))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSUymM3Z0kef"
      },
      "outputs": [],
      "source": [
        "result2 = perform_ocr(\"/content/sample3rd.png\")\n",
        "if result2 and len(result2) > 0:\n",
        "    data = result2[0]\n",
        "\n",
        "    texts = data.get('rec_texts', [])\n",
        "    scores = data.get('rec_scores', [])\n",
        "    polys = data.get('rec_polys', [])\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"EXTRACTED TEXT:\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for idx, (text, score) in enumerate(zip(texts, scores)):\n",
        "        print(f\"{idx+1}. {text} (confidence: {score:.2%})\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ALL TEXT COMBINED:\")\n",
        "    print(\"=\"*60)\n",
        "    print(' '.join(texts))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhSJoby22ISg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}